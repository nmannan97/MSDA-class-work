{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2253f8f5-0012-47b5-bc4d-f4114f772ea2",
   "metadata": {},
   "source": [
    "### Week 10 - Home work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9ca527-4a4e-4f34-894c-f2d003401fba",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "You need to finish all the sections and the points mentioned in each section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2eef5fd-0235-4d80-9077-bb246b899f00",
   "metadata": {},
   "source": [
    "# Section-1 \n",
    "You need to finish all the given points in a given section:\n",
    "\n",
    "       Update/Upgrade the NumPy package to the latest version\n",
    "       Install/Upgrade another package (e.g. Pandas)\n",
    "       Import NumPy as np\n",
    "       Use the np.array() function to create an array variable - array_1\n",
    "       E.g:\n",
    "        array([[ 10,  15],\n",
    "               [ 17, 100]])   \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e54aa70-3162-4e69-886b-5a34c0498826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([100, 110, 120, 130, 140])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np_1SD = np.array([100,110,120,130, 140])\n",
    "np_1SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "193b1dd4-6c0d-4c0c-add3-783a3d486035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200, 300, 400, 500, 600],\n",
       "       [430, 540, 650, 760, 870],\n",
       "       [110, 220, 330, 440, 550]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_2SD = np.array([[200,300,400,500,600], [430,540,650,760,870], [110,220,330,440,550]])\n",
    "np_2SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb14960-cdab-43ba-b98d-1eb6c4b48419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[100, 200, 300, 400, 500],\n",
       "        [110, 210, 310, 401, 510]],\n",
       "\n",
       "       [[110, 120, 130, 140, 150],\n",
       "        [510, 520, 530, 540, 500]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_3SD = np.array([[[100,200,300,400,500], [110,210,310,401,510]], [[110,120,130,140,150], [510,520,530,540,500]]])\n",
    "np_3SD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c5c7e2-3e94-4293-9bb5-1fc74ac9aa5c",
   "metadata": {},
   "source": [
    "# Section-2\n",
    "    * Generate 4 arrays of size 8\n",
    "     * 1st Array empty \"empty\"\n",
    "     * 2nd array full of  0s\n",
    "     * 3rd array full of 1s\n",
    "     * Last array full of 2s\n",
    "    * Generate 4 more arrays. This time, they should be 2 by 4 arrays.\n",
    "        * An empty array with the same shape as np_1SD. \n",
    "        * An 2-D array of 0s with the same shape as array_2D.\n",
    "        * A 3-D array of 1s with the same shappe as array_3D.\n",
    "        * A 3-D array of 2s with the same shape as array_3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d382e7f-13c4-4bc8-adcb-3fe37889bdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0 0 0 0 0 0 0 0]\n",
      "[1 1 1 1 1 1 1 1]\n",
      "[2 2 2 2 2 2 2 2]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "[[2 2 2 2]\n",
      " [2 2 2 2]]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.empty(8)\n",
    "arr2 = np.zeros(8, dtype=int)\n",
    "arr3 = np.ones(8, dtype=int)\n",
    "arr4 = np.full(8, 2, dtype=int)\n",
    "print(arr1)\n",
    "print(arr2)\n",
    "print(arr3)\n",
    "print(arr4)\n",
    "\n",
    "arr5 = np.empty((2, 4))\n",
    "arr6 = np.zeros((2, 4))\n",
    "arr7 = np.ones((2, 4))\n",
    "arr8 = np.full((2, 4), 2)\n",
    "print(arr5)\n",
    "print(arr6)\n",
    "print(arr7)\n",
    "print(arr8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d267678-3cde-481f-b9ba-2af37b1c6525",
   "metadata": {},
   "source": [
    "# Section -3 \n",
    "#### Using np.arange() function, solve following\n",
    "      Generate array from 0 to 40, excluding 40. \n",
    "      Generate Array 0 to 40, including 40. \n",
    "      Generate integers from 35 to 50, including 50. \n",
    "      Generate where 5-th integers from 35 to 50, including 50. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dc1bc5a-49c8-4efc-801e-cba1db974215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40]\n",
      "[35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50]\n",
      "[35 40 45 50]\n"
     ]
    }
   ],
   "source": [
    "arr1 = np.array(range(0, 40))\n",
    "print(arr1)\n",
    "arr1 = np.array(range(0, 41))\n",
    "print(arr1)\n",
    "arr1 = np.array(range(35, 51))\n",
    "print(arr1)\n",
    "arr1 = np.array(range(35, 51, 5))\n",
    "print(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8f47a-6164-463b-a2ab-11454032a431",
   "metadata": {},
   "source": [
    "# Section 4\n",
    "Generate the random value using numpy functions such as .random()\n",
    "\n",
    "    Use the probability to generate the single event\n",
    "    Array size of 8 with the probabilities of 8 events. \n",
    "    Array of 4 by 8 2 dimensional array with the probabilities of 40 events.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beafada-baa8-4d27-9e27-7b313e4d0a2e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "068e8a11-159f-4021-bf8b-6745db164c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['E31' 'E27' 'E28' 'E3' 'E17' 'E2' 'E25' 'E40']\n",
      " ['E19' 'E26' 'E5' 'E40' 'E38' 'E11' 'E26' 'E3']\n",
      " ['E27' 'E31' 'E23' 'E27' 'E6' 'E20' 'E27' 'E3']\n",
      " ['E33' 'E39' 'E21' 'E28' 'E11' 'E5' 'E16' 'E9']]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True, linewidth=150)\n",
    "events = [f\"E{i+1}\" for i in range(40)]\n",
    "probs = np.full(40, 1/40)\n",
    "array_4x8 = np.random.choice(events, size=(4, 8), p=probs)\n",
    "print(array_4x8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee309eea-c375-4f9d-9afd-24e93b855f2d",
   "metadata": {},
   "source": [
    "# Section 5\n",
    "    Import the file and display it contents. You can use loadtxt(). You can use the file creditor-total-price.csv\n",
    "    Import the file and display it contents. You can use np.genfromtxt(). You can use the file creditor-total-price.csv\n",
    "        Set the data type to strings. \n",
    "        Skip the first row of the dataset. \n",
    "        Skip the last 15 rows of the dataset. \n",
    "        Only pull data from the 2nd, 3rd and 5th columns. \n",
    "\n",
    "\n",
    "Hint: By default np.loadtxt() asusmes all the values will be numeric, so it crashes when it encounters text data. We can bypass this by specifying the datatype to NumPy strings when importing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ddf379a6-2c15-49ca-a2ec-d9a168548659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Masters Data Analytics\\MSDA-class-work\\DATA-200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string 'uid_1' to float64 at row 0, column 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'uid_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mMasters Data Analytics\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mMSDA-class-work\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDATA-200\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mcreditors-LT.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1395\u001b[0m, in \u001b[0;36mloadtxt\u001b[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(delimiter, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1393\u001b[0m     delimiter \u001b[38;5;241m=\u001b[39m delimiter\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1395\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m            \u001b[49m\u001b[43munpack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mndmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1046\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     data \u001b[38;5;241m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_dtype_via_object_chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1046\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_filelike\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimaginary_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimaginary_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1049\u001b[0m \u001b[43m        \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musecols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskiplines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiplines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_rows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilelike\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilelike\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbyte_converters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbyte_converters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;66;03m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[0;32m   1059\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filelike:\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string 'uid_1' to float64 at row 0, column 2."
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "data = np.loadtxt(\"E:\\\\Masters Data Analytics\\\\MSDA-class-work\\\\DATA-200\\\\creditors-LT.csv\", delimiter=',', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e506ee-1e6b-4084-9914-cb0fabd6cd27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Section 6 \n",
    "    Slice the first column of the np_2SD array\n",
    "    array([200, 430, 110])\n",
    "    Slice the last column of the np_2SD  array\n",
    "    array([600, 870, 550])\n",
    "    Slice the second row of the np_2SD array\n",
    "    array([430, 540, 650, 760, 870])\n",
    "    Slice the last two columns of the np_2SD row of the np_2SD array\n",
    "    array([760, 870])\n",
    "    Slice the 2-nd row of the np_2SD array excluding the last two columns\n",
    "    array([430, 540, 650])\n",
    "    Slice everything excluding the first row and last column of the np_2SD array\n",
    "    array([[430, 540, 650, 760],\n",
    "           [110, 220, 330, 440]])\n",
    "    Slice the 1st, 3rd and 5th columns of the np_3SD array\n",
    "    array([[ 1, 11],\n",
    "           [11, 51]])\n",
    "    Slice every other column of both matrices in the np_3SD array\n",
    "    array([[[ 10,  30,  50],\n",
    "            [110, 310, 510]],\n",
    "    \n",
    "           [[110, 130, 150],\n",
    "            [510, 530,  50]]])\n",
    "    Use conditional slicing to check if the individual elements of each array satisfy a given condition on np_1SD(e.g. greater than 8)\n",
    "    array([False,  True,  True,  True,  True])\n",
    "    Add a second condition and disaply which individual elements satisfy both np_1SD , np_2SD and np_3SD (e.g. greater than 10 and odd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8864f-8350-4f4f-b472-76b39b4662a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
